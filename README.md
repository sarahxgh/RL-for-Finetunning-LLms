# RL-for-Finetunning-LLms
### üì¶ Repository: `LLM-Toxicity-Mitigation`  #### üß† Project Overview:  This repository contains the full implementation and evaluation code for our project on mitigating toxicity in large language models (LLMs) using three different fine-tuning methods: **Supervised Fine-Tuning (SFT)**, **Proximal Policy Optimization (PPO)**, and **Direct Preference Optimization (DPO)**. The target model is [TinyLlama-1.1B](https://huggingface.co/csarron/TinyLlama-1.1B-Chat-v1.0), and the dataset used is [`unalignment/toxic-dpo-v0.2`](https://huggingface.co/datasets/unalignment/toxic-dpo-v0.2).  The goal is to compare these methods under identical settings in terms of safety alignment, particularly with respect to reducing output toxicity, and to assess their trade-offs in terms of performance, simplicity, and efficiency.  ---  ### üìÅ Contents  * **`DataPrep.ipynb`**   Prepares the dataset for training by formatting prompt‚Äìresponse pairs, filtering entries, and optionally extracting chosen/rejected samples for DPO and PPO pipelines. Includes tokenization and splitting routines.  * **`SFT.ipynb`**   Implements Supervised Fine-Tuning on the TinyLlama model using only the preferred (chosen) responses from the dataset. Uses cross-entropy loss and LoRA adapters for efficient updates.  * **`PPO.ipynb`**   Trains the model using Proximal Policy Optimization with rewards derived from Detoxify-based toxicity scores. Includes KL control and multiple PPO passes per batch.  * **`DPO.ipynb`**   Implements Direct Preference Optimization by contrasting preferred and rejected responses without training a reward model. Uses a contrastive log-ratio loss between model and reference outputs.  * **`Report/`**   Contains the LaTeX source files and figures used to generate the final project report, including results analysis, charts, and formatted references.  ---  ### üõ† Requirements  * Python 3.10+ * Hugging Face Transformers * `trl`, `accelerate`, `peft`, `Detoxify`, and other dependencies listed in `requirements.txt`.  ---  Let me know if you‚Äôd like to generate a `README.md`, or include setup instructions, sample outputs, or demo links!
